{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from importlib import reload\n",
    "from tqdm.notebook import tqdm\n",
    "import pytorch_lightning as pl\n",
    "from transformers import GPT2Config, GPT2Tokenizer\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'batch_size': 32,\n",
       "  'max_len': 256,\n",
       "  'csv_file': 'data/processed.csv',\n",
       "  'tokenizer_name': 'microsoft/DialoGPT-small',\n",
       "  'val_frac': 0.1},\n",
       " 'model': {'n_positions': 256,\n",
       "  'n_ctx': 256512,\n",
       "  'n_embd': 768,\n",
       "  'n_layer': 6,\n",
       "  'n_head': 12,\n",
       "  'n_inner': 1024},\n",
       " 'opt': {'lr': 5e-05, 'max_epochs': 100, 'weight_decay': 0.001}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "config = yaml.load(open('configs/config.yaml'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(config['data']['tokenizer_name'])\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'batch_size': 32,\n",
       "  'max_len': 256,\n",
       "  'csv_file': 'processed.csv',\n",
       "  'tokenizer_name': 'microsoft/DialoGPT-small',\n",
       "  'val_frac': 0.1},\n",
       " 'model': {'n_positions': 256,\n",
       "  'n_ctx': 256512,\n",
       "  'n_embd': 768,\n",
       "  'n_layer': 6,\n",
       "  'n_head': 12,\n",
       "  'n_inner': 1024,\n",
       "  'vocab_size': 50257,\n",
       "  'pad_token_id': 50256,\n",
       "  'eos_token_id': 50256,\n",
       "  'bos_token_id': 50256},\n",
       " 'opt': {'lr': 5e-05, 'max_epochs': 100, 'weight_decay': 0.001},\n",
       " 'exp': {'save_dir': 'weights/',\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'max_grad_norm': 1.0}}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['model']['vocab_size'] = tokenizer.vocab_size\n",
    "config['model']['pad_token_id'] = tokenizer.pad_token_id\n",
    "config['model']['eos_token_id'] = tokenizer.eos_token_id\n",
    "config['model']['bos_token_id'] = tokenizer.bos_token_id\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config['data']['csv_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc2714b84ea4fcfbf18cf359a3e12a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contexted = []\n",
    "n = 7\n",
    "for i in tqdm(range(n, len(df['text']))):\n",
    "    row = []\n",
    "    prev = i - 1 - n # we additionally substract 1, so row will contain current responce and 7 previous responces  \n",
    "    for j in range(i, prev, -1):\n",
    "        row.append(df['text'][j])\n",
    "    contexted.append(row)  \n",
    "    \n",
    "columns = ['response', 'context'] \n",
    "columns = columns + ['context/'+str(i) for i in range(n-1)]\n",
    "df = pd.DataFrame.from_records(contexted, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 93291 samples and val dataset has 10365 samples\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "reload(dataset)\n",
    "from dataset import get_dataloaders\n",
    "\n",
    "train_loader, val_loader = get_dataloaders(tokenizer, df, \n",
    "                                           max_len=config['data']['max_len'], \n",
    "                                           batch_size=config['data']['batch_size'], \n",
    "                                           val_frac=config['data']['val_frac'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "reload(model)\n",
    "from model import ErfBot\n",
    "\n",
    "\n",
    "model = ErfBot(config=GPT2Config(**config['model']), \n",
    "               **config['opt'])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\n",
    "    save_dir='logs/',\n",
    "    name='gpt2_logs'\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(dirpath='weights/gpt2', \n",
    "                             filename='{epoch}-{val_loss:.2f}', \n",
    "                             monitor='val_loss',\n",
    "                             save_top_k=1, \n",
    "                             period=1)\n",
    "\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "## defining trainer\n",
    "trainer = Trainer(benchmark=True, \n",
    "                  gpus=1, \n",
    "                  logger=logger, \n",
    "                  max_epochs=config['opt']['max_epochs'],\n",
    "                  callbacks=[checkpoint, lr_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
